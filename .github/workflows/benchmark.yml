name: AsyncLocalStorage Benchmark

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      iterations:
        description: 'Number of iterations per version (default: 10)'
        required: false
        default: '10'
        type: number
      run_memory_tests:
        description: 'Run memory profiling tests'
        required: false
        default: 'true'
        type: boolean

jobs:
  benchmark:
    runs-on: ubuntu-latest-4-cores
    strategy:
      matrix:
        node-version: ['16.20.2', '18.19.1', '20.11.0', '21.7.3', '22.18.0', '24.6.0']
      fail-fast: false
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Setup Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Verify Node.js version
      run: |
        echo "Expected Node.js version: ${{ matrix.node-version }}"
        echo "Actual Node.js version: $(node --version)"
        if [ "$(node --version)" != "v${{ matrix.node-version }}" ]; then
          echo "❌ Node.js version mismatch!"
          exit 1
        fi
        echo "✅ Node.js version verified"
    
    - name: Debug matrix info
      run: |
        echo "🔍 Debug information:"
        echo "Matrix node-version: ${{ matrix.node-version }}"
        echo "Current working directory: $(pwd)"
        echo "Node.js version: $(node --version)"
        echo "NPM version: $(npm --version)"
        echo "Available scripts:"
        npm run
    
    - name: Run multi-iteration benchmarks
      run: |
        echo "🚀 Running ${{ github.event.inputs.iterations || 10 }} iterations for Node.js ${{ matrix.node-version }}"
        
        # Ensure results directory exists
        mkdir -p results/versions/node_${{ matrix.node-version }}
        echo "📁 Created results directory: results/versions/node_${{ matrix.node-version }}"
        
        # Run the benchmark
        npm run multi-iteration ${{ github.event.inputs.iterations || 10 }}
        
        # Verify results were created
        echo "📊 Benchmark completed, checking results:"
        ls -la results/versions/node_${{ matrix.node-version }}/ || echo "No results directory found"
        
    - name: Run memory profiling tests
      if: ${{ github.event.inputs.run_memory_tests != 'false' }}
      run: |
        echo "🧠 Running memory tests for Node.js ${{ matrix.node-version }}"
        
        # Ensure results directory exists
        mkdir -p results/versions/node_${{ matrix.node-version }}
        
        # Run memory test
        node --expose-gc src/memory-test.js
        
        # Copy memory results to version directory
        if [ -d "results/versions/node_${{ matrix.node-version }}" ]; then
          mkdir -p "results/versions/node_${{ matrix.node-version }}/memory"
          find results -name "memory_*.json" -exec cp {} "results/versions/node_${{ matrix.node-version }}/memory/" \;
          
          echo "📊 Memory test results:"
          ls -la "results/versions/node_${{ matrix.node-version }}/memory/" || echo "No memory results found"
        fi
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-node-${{ matrix.node-version }}
        path: |
          results/versions/node_${{ matrix.node-version }}/
          results/benchmark_*.json
          results/memory_*.json
        retention-days: 30
    
    - name: Generate performance summary
      run: |
        echo "## Performance Summary for Node.js ${{ matrix.node-version }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        VERSION_DIR="results/versions/node_${{ matrix.node-version }}"
        if [ -d "$VERSION_DIR" ]; then
          echo "### Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "**Iterations completed:** $(find $VERSION_DIR -name "iteration_*" -type d | wc -l)" >> $GITHUB_STEP_SUMMARY
          echo "**Total duration:** $(find $VERSION_DIR -name "iteration-summary.json" -exec jq -r '.summary.averageDuration // "N/A"' {} \;)" >> $GITHUB_STEP_SUMMARY
          
          # Show iteration summary if available
          if [ -f "$VERSION_DIR/iteration-summary.json" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Iteration Summary:**" >> $GITHUB_STEP_SUMMARY
            echo '```json' >> $GITHUB_STEP_SUMMARY
            jq '.summary' "$VERSION_DIR/iteration-summary.json" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "⚠️ No results directory found for this version" >> $GITHUB_STEP_SUMMARY
        fi

  compare-versions:
    runs-on: ubuntu-latest-4-cores
    needs: [benchmark]
    if: always()
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Download all benchmark results
      uses: actions/download-artifact@v4
      with:
        path: ./downloaded-results
      continue-on-error: true
    
    - name: Setup Node.js (latest)
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Prepare results directory
      run: |
        mkdir -p results/versions
        
        # Copy all downloaded results to the results directory
        if [ -d "./downloaded-results" ]; then
          for artifact in downloaded-results/*/; do
            if [ -d "$artifact" ]; then
              echo "Processing artifact: $artifact"
              # Extract version from artifact name
              version_name=$(basename "$artifact" | sed 's/benchmark-results-node-//')
              target_dir="results/versions/node_$version_name"
              
              echo "Copying to: $target_dir"
              cp -r "$artifact"/* "$target_dir/" 2>/dev/null || true
              
              # Ensure proper structure
              if [ ! -d "$target_dir" ]; then
                mkdir -p "$target_dir"
              fi
            fi
          done
        else
          echo "No downloaded artifacts found, checking for existing results..."
        fi
        
        # Check if we have any existing results
        if [ -d "results/versions" ] && [ "$(ls -A results/versions)" ]; then
          echo "Found existing benchmark results:"
          ls -la results/versions/
        else
          echo "No benchmark results found, creating placeholder structure..."
          mkdir -p results/versions/placeholder
          echo '{"message": "No benchmark data available", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}' > results/versions/placeholder/placeholder.json
        fi
        
        echo "Final results structure:"
        find results/versions -type d | head -20
    
    - name: Generate version comparison report
      run: |
        echo "🔍 Generating comprehensive version comparison report..."
        if npm run compare-versions; then
          echo "📊 Comparison report generated successfully"
          ls -la docs/
        else
          echo "⚠️ Version comparison failed, but continuing..."
          # Create a basic placeholder report
          mkdir -p docs
          echo "# AsyncLocalStorage Benchmark Results" > docs/index.md
          echo "" >> docs/index.md
          echo "No benchmark data available at this time." >> docs/index.md
          echo "" >> docs/index.md
          echo "Generated on: $(date -u)" >> docs/index.md
        fi
    
    - name: Generate additional reports
      run: |
        echo "📝 Generating additional performance reports..."
        if npm run generate-report; then
          echo "📈 Additional reports generated successfully"
          ls -la docs/
        else
          echo "⚠️ Report generation failed, but continuing..."
          # Ensure we have at least some documentation
          if [ ! -f "docs/index.md" ]; then
            mkdir -p docs
            echo "# AsyncLocalStorage Benchmark Results" > docs/index.md
            echo "" >> docs/index.md
            echo "No benchmark data available at this time." >> docs/index.md
            echo "" >> docs/index.md
            echo "Generated on: $(date -u)" >> docs/index.md
          fi
        fi
    
    - name: Upload comparison results
      uses: actions/upload-artifact@v4
      with:
        name: version-comparison
        path: |
          results/
          docs/
        retention-days: 30

  performance-regression:
    runs-on: ubuntu-latest-4-cores
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Download benchmark results
      uses: actions/download-artifact@v4
      with:
        name: benchmark-results-node-20.11.0
        path: ./pr-results
    
    - name: Checkout main branch
      uses: actions/checkout@v4
      with:
        ref: main
        path: ./main-branch
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.11.0'
        cache: 'npm'
    
    - name: Run baseline benchmark (main branch)
      working-directory: ./main-branch
      run: |
        npm ci
        npm run benchmark
        mkdir -p ../baseline-results
        cp results/benchmark_*.json ../baseline-results/
    
    - name: Compare performance
      run: |
        echo "## Performance Regression Analysis" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        BASELINE=$(ls baseline-results/benchmark_*.json | head -1)
        CURRENT=$(ls pr-results/benchmark_*.json | head -1)
        
        if [ -f "$BASELINE" ] && [ -f "$CURRENT" ]; then
          echo "Comparing performance between main branch and PR..." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Baseline (main branch)" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          jq '.benchmarks[] | {name: .name, overhead: .overhead.timePercent}' "$BASELINE" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Current (PR)" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          jq '.benchmarks[] | {name: .name, overhead: .overhead.timePercent}' "$CURRENT" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        else
          echo "⚠️ Could not find benchmark files for comparison" >> $GITHUB_STEP_SUMMARY
        fi
