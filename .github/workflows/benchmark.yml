name: AsyncLocalStorage Benchmark

on:
  push:
    branches: [ performance-test ]
  schedule:
    # Run weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      iterations:
        description: 'Number of iterations per version (default: 10)'
        required: false
        default: '10'
        type: number
      run_memory_tests:
        description: 'Run memory profiling tests'
        required: false
        default: 'true'
        type: boolean

permissions:
  contents: write
  actions: read

jobs:
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
    
    - name: Generate version matrix
      id: set-matrix
      run: |
        echo "🔍 Reading Node.js versions from config..."
        VERSIONS=$(node -e "
          const config = require('./config/node-versions.json');
          const activeVersions = Object.entries(config.versions)
            .filter(([key, version]) => version.active)
            .map(([key, version]) => version.exact)
            .sort((a, b) => {
              const aParts = a.split('.').map(Number);
              const bParts = b.split('.').map(Number);
              for (let i = 0; i < Math.max(aParts.length, bParts.length); i++) {
                const aPart = aParts[i] || 0;
                const bPart = bParts[i] || 0;
                if (aPart !== bPart) return aPart - bPart;
              }
              return 0;
            });
          console.log(JSON.stringify(activeVersions));
        ")
        
        echo "📋 Found versions: $VERSIONS"
        echo "matrix={\"node-version\":$VERSIONS}" >> $GITHUB_OUTPUT
        
        echo "🎯 Matrix will run ${#VERSIONS[@]} Node.js versions in parallel"

  benchmark:
    runs-on: ubuntu-latest-4-cores
    needs: generate-matrix
    strategy:
      matrix: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}
      fail-fast: false
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Setup Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Verify Node.js version
      run: |
        echo "Expected Node.js version: ${{ matrix.node-version }}"
        echo "Actual Node.js version: $(node --version)"
        if [ "$(node --version)" != "v${{ matrix.node-version }}" ]; then
          echo "❌ Node.js version mismatch!"
          exit 1
        fi
        echo "✅ Node.js version verified"
    
    - name: Debug matrix info
      run: |
        echo "🔍 Debug information:"
        echo "Matrix node-version: ${{ matrix.node-version }}"
        echo "Current working directory: $(pwd)"
        echo "Node.js version: $(node --version)"
        echo "NPM version: $(npm --version)"
        echo "Available scripts:"
        npm run
        echo "Matrix strategy info:"
        echo "Total matrix jobs: ${{ strategy.job-total }}"
        echo "Current matrix index: ${{ strategy.job-index }}"
    
    - name: Run multi-iteration benchmarks
      env:
        NODE_VERSION: ${{ matrix.node-version }}
      run: |
        echo "🚀 Running ${{ github.event.inputs.iterations || 10 }} iterations for Node.js ${{ matrix.node-version }}"
        echo "📊 Matrix job ${{ strategy.job-index }} of ${{ strategy.job-total }}"
        
        # Ensure results directory exists
        mkdir -p results/versions/node_${{ matrix.node-version }}
        echo "📁 Created results directory: results/versions/node_${{ matrix.node-version }}"
        
        # Run the benchmark
        npm run multi-iteration ${{ github.event.inputs.iterations || 10 }}
        
        # Verify results were created
        echo "📊 Benchmark completed, checking results:"
        ls -la results/versions/node_${{ matrix.node-version }}/ || echo "No results directory found"
        
    - name: Run memory profiling tests
      if: ${{ github.event.inputs.run_memory_tests != 'false' }}
      run: |
        echo "🧠 Running memory tests for Node.js ${{ matrix.node-version }}"
        
        # Ensure results directory exists
        mkdir -p results/versions/node_${{ matrix.node-version }}
        
        # Run memory test
        node --expose-gc src/memory-test.js
        
        # Copy memory results to version directory
        if [ -d "results/versions/node_${{ matrix.node-version }}" ]; then
          mkdir -p "results/versions/node_${{ matrix.node-version }}/memory"
          find results -name "memory_*.json" -exec cp {} "results/versions/node_${{ matrix.node-version }}/memory/" \;
          
          echo "📊 Memory test results:"
          ls -la "results/versions/node_${{ matrix.node-version }}/memory/" || echo "No memory results found"
        fi
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-node-${{ matrix.node-version }}
        path: |
          results/versions/node_${{ matrix.node-version }}/
          results/benchmark_*.json
          results/memory_*.json
        retention-days: 30
    
    - name: Generate performance summary
      run: |
        echo "## Performance Summary for Node.js ${{ matrix.node-version }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        VERSION_DIR="results/versions/node_${{ matrix.node-version }}"
        if [ -d "$VERSION_DIR" ]; then
          echo "### Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "**Iterations completed:** $(find $VERSION_DIR -name "iteration_*" -type d | wc -l)" >> $GITHUB_STEP_SUMMARY
          echo "**Total duration:** $(find $VERSION_DIR -name "iteration-summary.json" -exec jq -r '.summary.averageDuration // "N/A"' {} \;)" >> $GITHUB_STEP_SUMMARY
          
          # Show iteration summary if available
          if [ -f "$VERSION_DIR/iteration-summary.json" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Iteration Summary:**" >> $GITHUB_STEP_SUMMARY
            echo '```json' >> $GITHUB_STEP_SUMMARY
            jq '.summary' "$VERSION_DIR/iteration-summary.json" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "⚠️ No results directory found for this version" >> $GITHUB_STEP_SUMMARY
        fi

  compare-versions:
    runs-on: ubuntu-latest-4-cores
    needs: [benchmark]
    if: always()
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Download all benchmark results
      uses: actions/download-artifact@v4
      with:
        path: ./downloaded-results
        pattern: 'benchmark-results-node-*'
      continue-on-error: true
    
    - name: Setup Node.js (latest)
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Prepare results directory
      run: |
        mkdir -p results/versions
        
        # Copy all downloaded results to the results directory
        if [ -d "./downloaded-results" ]; then
          for artifact in downloaded-results/*/; do
            if [ -d "$artifact" ]; then
              echo "Processing artifact: $artifact"
              # Extract version from artifact name
              version_name=$(basename "$artifact" | sed 's/benchmark-results-node-//')
              target_dir="results/versions/node_$version_name"
              
              echo "Copying to: $target_dir"
              cp -r "$artifact"/* "$target_dir/" 2>/dev/null || true
              
              # Ensure proper structure
              if [ ! -d "$target_dir" ]; then
                mkdir -p "$target_dir"
              fi
            fi
          done
        else
          echo "No downloaded artifacts found, checking for existing results..."
        fi
        
        # Check if we have any existing results
        if [ -d "results/versions" ] && [ "$(ls -A results/versions)" ]; then
          echo "Found existing benchmark results:"
          ls -la results/versions/
        else
          echo "No benchmark results found, creating placeholder structure..."
          mkdir -p results/versions/placeholder
          echo '{"message": "No benchmark data available", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}' > results/versions/placeholder/placeholder.json
        fi
        
        echo "Final results structure:"
        find results/versions -type d | head -20
    
    - name: Generate version comparison report
      run: |
        echo "🔍 Generating comprehensive version comparison report..."
        if npm run compare-versions; then
          echo "📊 Comparison report generated successfully"
          ls -la docs/
        else
          echo "⚠️ Version comparison failed, but continuing..."
          # Create a basic placeholder report
          mkdir -p docs
          echo "# AsyncLocalStorage Benchmark Results" > docs/index.md
          echo "" >> docs/index.md
          echo "No benchmark data available at this time." >> docs/index.md
          echo "" >> docs/index.md
          echo "Generated on: $(date -u)" >> docs/index.md
        fi
    
    - name: Generate additional reports
      run: |
        echo "📝 Generating additional performance reports..."
        if npm run generate-report; then
          echo "📈 Additional reports generated successfully"
          ls -la docs/
        else
          echo "⚠️ Report generation failed, but continuing..."
          # Ensure we have at least some documentation
          if [ ! -f "docs/index.md" ]; then
            mkdir -p docs
            echo "# AsyncLocalStorage Benchmark Results" > docs/index.md
            echo "" >> docs/index.md
            echo "No benchmark data available at this time." >> docs/index.md
            echo "" >> docs/index.md
            echo "Generated on: $(date -u)" >> docs/index.md
          fi
        fi
    
    - name: Upload comparison results
      uses: actions/upload-artifact@v4
      with:
        name: version-comparison
        path: |
          results/
          docs/
        retention-days: 30

  create-release:
    runs-on: ubuntu-latest
    needs: [compare-versions]
    if: always() && github.ref == 'refs/heads/performance-test'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Download comparison results
      uses: actions/download-artifact@v4
      with:
        name: version-comparison
        path: ./release-assets
      continue-on-error: true
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Prepare release assets
      id: prepare_release
      run: |
        echo "📦 Preparing release assets..."
        
        # Create a timestamp for the release
        TIMESTAMP=$(date -u +"%Y%m%d-%H%M%S")
        RELEASE_TAG="benchmark-results-${TIMESTAMP}"
        
        # Create release directory
        mkdir -p release-package
        
        # Copy benchmark results and docs
        if [ -d "./release-assets/results" ]; then
          cp -r ./release-assets/results release-package/
        fi
        
        if [ -d "./release-assets/docs" ]; then
          cp -r ./release-assets/docs release-package/
        fi
        
        # Create a summary file
        cat > release-package/README.md << EOF
# AsyncLocalStorage Benchmark Results

Generated on: $(date -u)

## Contents
- \`results/\` - Raw benchmark data for each Node.js version
- \`docs/\` - Generated reports and analysis

## Usage
Download this release and extract the contents to use with the async-node-stats application.

## Node.js Versions Tested
$(find release-package/results/versions -maxdepth 1 -type d -name "node_*" | sort | sed 's|.*/||' | sed 's/^/- /')
EOF
        
        # Create a JSON manifest
        cat > release-package/manifest.json << EOF
{
  "releaseType": "benchmark-results",
  "generatedAt": "$(date -u -Iseconds)",
  "nodeVersions": [
$(find release-package/results/versions -maxdepth 1 -type d -name "node_*" | sort | sed 's|.*/||' | sed 's/^/    "/' | sed 's/$/",/' | sed '$ s/,$//')
  ],
  "totalSize": "$(du -sh release-package | cut -f1)",
  "workflowRun": "${{ github.run_id }}"
}
EOF
        
        # Create a compressed archive
        tar -czf "async-node-stats-benchmark-${TIMESTAMP}.tar.gz" -C release-package .
        
        echo "Release tag: $RELEASE_TAG"
        echo "Release assets prepared:"
        ls -la release-package/
        echo "Archive created: async-node-stats-benchmark-${TIMESTAMP}.tar.gz"
        
        # Set outputs for the next step
        echo "release_tag=${RELEASE_TAG}" >> $GITHUB_OUTPUT
        echo "archive_name=async-node-stats-benchmark-${TIMESTAMP}.tar.gz" >> $GITHUB_OUTPUT
    
    - name: Create Release
      id: create_release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ steps.prepare_release.outputs.release_tag }}
        release_name: "Benchmark Results - ${{ steps.prepare_release.outputs.release_tag }}"
        body: |
          ## AsyncLocalStorage Benchmark Results
          
          This release contains the latest benchmark results for AsyncLocalStorage performance across different Node.js versions.
          
          ### What's Included
          - Raw benchmark data for each tested Node.js version
          - Generated performance reports and analysis
          - Memory profiling results
          - Version comparison charts and tables
          
          ### Generated On
          ${{ steps.prepare_release.outputs.generated_at }}
          
          ### Workflow Run
          [${{ github.workflow }} #${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
          
          ### Usage
          Download the \`async-node-stats-benchmark-*.tar.gz\` file and extract it to use with the async-node-stats application.
          
          The deploy workflow will automatically download and use the latest release for building the site.
        draft: false
        prerelease: false
    
    - name: Upload Release Assets
      uses: actions/upload-release-asset@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        upload_url: ${{ steps.create_release.outputs.upload_url }}
        asset_path: ./${{ steps.prepare_release.outputs.archive_name }}
        asset_name: ${{ steps.prepare_release.outputs.archive_name }}
        asset_content_type: application/gzip
    
    - name: Upload Release Assets - Individual Files
      uses: actions/upload-release-asset@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        upload_url: ${{ steps.create_release.outputs.upload_url }}
        asset_path: ./release-package/manifest.json
        asset_name: manifest.json
        asset_content_type: application/json
    
    - name: Upload Release Assets - Results Directory
      run: |
        cd release-package
        zip -r ../results.zip results/
        cd ..
      
    - name: Upload Release Assets - Results Zip
      uses: actions/upload-release-asset@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        upload_url: ${{ steps.create_release.outputs.upload_url }}
        asset_path: ./results.zip
        asset_name: results.zip
        asset_content_type: application/zip

  performance-regression:
    runs-on: ubuntu-latest-4-cores
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Download benchmark results
      uses: actions/download-artifact@v4
      with:
        name: benchmark-results-node-20.11.0
        path: ./pr-results
    
    - name: Checkout main branch
      uses: actions/checkout@v4
      with:
        ref: main
        path: ./main-branch
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.11.0'
        cache: 'npm'
    
    - name: Run baseline benchmark (main branch)
      working-directory: ./main-branch
      run: |
        npm ci
        npm run benchmark
        mkdir -p ../baseline-results
        cp results/benchmark_*.json ../baseline-results/
    
    - name: Compare performance
      run: |
        echo "## Performance Regression Analysis" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        BASELINE=$(ls baseline-results/benchmark_*.json | head -1)
        CURRENT=$(ls pr-results/benchmark_*.json | head -1)
        
        if [ -f "$BASELINE" ] && [ -f "$CURRENT" ]; then
          echo "Comparing performance between main branch and PR..." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Baseline (main branch)" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          jq '.benchmarks[] | {name: .name, overhead: .overhead.timePercent}' "$BASELINE" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Current (PR)" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          jq '.benchmarks[] | {name: .name, overhead: .overhead.timePercent}' "$CURRENT" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        else
          echo "⚠️ Could not find benchmark files for comparison" >> $GITHUB_STEP_SUMMARY
        fi
