name: AsyncLocalStorage Benchmark

on:
  push:
    branches: [ main ]
  schedule:
    # Run weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      iterations:
        description: 'Number of iterations per version (default: 2)'
        required: false
        default: '2'
        type: number
      run_memory_tests:
        description: 'Run memory profiling tests'
        required: false
        default: 'true'
        type: boolean

permissions:
  contents: write
  actions: read

jobs:
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
    
    - name: Generate version matrix
      id: set-matrix
      run: |
        echo "🔍 Reading Node.js versions from config..."
        VERSIONS=$(node -e "
          const config = require('./config/node-versions.json');
          const activeVersions = Object.entries(config.versions)
            .filter(([key, version]) => version.active)
            .map(([key, version]) => version.exact)
            .sort((a, b) => {
              const aParts = a.split('.').map(Number);
              const bParts = b.split('.').map(Number);
              for (let i = 0; i < Math.max(aParts.length, bParts.length); i++) {
                const aPart = aParts[i] || 0;
                const bPart = bParts[i] || 0;
                if (aPart !== bPart) return aPart - bPart;
              }
              return 0;
            });
          console.log(JSON.stringify(activeVersions));
        ")
        
        echo "📋 Found versions: $VERSIONS"
        echo "matrix={\"node-version\":$VERSIONS}" >> $GITHUB_OUTPUT
        
        echo "🎯 Matrix will run ${#VERSIONS[@]} Node.js versions in parallel"

  benchmark:
    runs-on: ubuntu-latest-4-cores
    needs: generate-matrix
    strategy:
      matrix: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}
      fail-fast: false
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Setup Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Verify Node.js version
      run: |
        echo "Expected Node.js version: ${{ matrix.node-version }}"
        echo "Actual Node.js version: $(node --version)"
        if [ "$(node --version)" != "v${{ matrix.node-version }}" ]; then
          echo "❌ Node.js version mismatch!"
          exit 1
        fi
        echo "✅ Node.js version verified"
    
    - name: Debug matrix info
      run: |
        echo "🔍 Debug information:"
        echo "Matrix node-version: ${{ matrix.node-version }}"
        echo "GitHub run ID: ${{ github.run_id }}"
        echo "GitHub run number: ${{ github.run_number }}"
        echo "GitHub ref: ${{ github.ref }}"
        echo "GitHub event name: ${{ github.event_name }}"
        echo "GitHub actor: ${{ github.actor }}"
        echo "GitHub repository: ${{ github.repository }}"
        echo "GitHub workspace: ${{ github.workspace }}"
        echo "Runner OS: ${{ runner.os }}"
        echo "Runner architecture: ${{ runner.arch }}"
        echo "Runner temp: ${{ runner.temp }}"
        echo "Runner tool cache: ${{ runner.tool_cache }}"
    
    - name: Run benchmark tests
      id: benchmark
      run: |
        echo "🚀 Starting AsyncLocalStorage benchmark for Node.js ${{ matrix.node-version }}"
        echo "📊 Running with iterations: ${{ github.event.inputs.iterations || '2' }}"
        echo "🧠 Memory tests enabled: ${{ github.event.inputs.run_memory_tests || 'true' }}"
        
        # Set environment variables for the benchmark
        export NODE_VERSION="${{ matrix.node-version }}"
        export ITERATIONS="${{ github.event.inputs.iterations || '2' }}"
        export RUN_MEMORY_TESTS="${{ github.event.inputs.run_memory_tests || 'true' }}"
        export GITHUB_RUN_ID="${{ github.run_id }}"
        export GITHUB_RUN_NUMBER="${{ github.run_number }}"
        
        echo "🔧 Environment variables set:"
        echo "  NODE_VERSION: $NODE_VERSION"
        echo "  ITERATIONS: $ITERATIONS"
        echo "  RUN_MEMORY_TESTS: $RUN_MEMORY_TESTS"
        echo "  GITHUB_RUN_ID: $GITHUB_RUN_ID"
        echo "  GITHUB_RUN_NUMBER: $GITHUB_RUN_NUMBER"
        
        # Run the benchmark
        echo "🏃‍♂️ Executing benchmark..."
        if npm run benchmark; then
          echo "✅ Benchmark completed successfully"
          
          # Check what was generated
          echo "📁 Benchmark results generated:"
          find public/results/ -name "*.json" -type f | head -10
          
          # Set output for next steps
          echo "benchmark_success=true" >> $GITHUB_OUTPUT
        else
          echo "❌ Benchmark failed with exit code $?"
          echo "benchmark_success=false" >> $GITHUB_OUTPUT
          exit 1
        fi
    
    - name: Run memory tests (conditional)
      id: memory_test
      if: github.event.inputs.run_memory_tests != 'false'
      run: |
        echo "🧠 Starting memory profiling tests for Node.js ${{ matrix.node-version }}"
        
        # Set environment variables for memory tests
        export NODE_VERSION="${{ matrix.node-version }}"
        export GITHUB_RUN_ID="${{ github.run_id }}"
        export GITHUB_RUN_NUMBER="${{ github.run_number }}"
        
        echo "🔧 Memory test environment variables:"
        echo "  NODE_VERSION: $NODE_VERSION"
        echo "  GITHUB_RUN_ID: $GITHUB_RUN_ID"
        echo "  GITHUB_RUN_NUMBER: $GITHUB_RUN_NUMBER"
        
        # Run memory tests
        echo "🏃‍♂️ Executing memory tests..."
        if npm run memory-test; then
          echo "✅ Memory tests completed successfully"
          
          # Check what was generated
          echo "📁 Memory test results generated:"
          find public/results/ -name "*memory*" -type f | head -10
          
          # Set output for next steps
          echo "memory_test_success=true" >> $GITHUB_OUTPUT
        else
          echo "❌ Memory tests failed with exit code $?"
          echo "memory_test_success=false" >> $GITHUB_OUTPUT
          # Don't fail the workflow for memory test failures
        fi
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-node-${{ matrix.node-version }}
        path: public/results/
        retention-days: 30

  create-release:
    runs-on: ubuntu-latest
    needs: [benchmark]
    if: always() && github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Download all benchmark results
      uses: actions/download-artifact@v4
      with:
        path: ./downloaded-results
        pattern: 'benchmark-results-node-*'
      continue-on-error: true
    
    - name: Debug downloaded artifacts
      run: |
        echo "🔍 Debugging downloaded artifacts..."
        echo "Current directory: $(pwd)"
        
        if [ -d "./downloaded-results" ]; then
          echo "✅ Downloaded results directory exists"
          echo "📁 Contents of ./downloaded-results/:"
          ls -la ./downloaded-results/
          
          echo ""
          echo "📦 Individual artifact contents:"
          for artifact_dir in downloaded-results/*/; do
            if [ -d "$artifact_dir" ]; then
              echo "  📂 $(basename "$artifact_dir"):"
              ls -la "$artifact_dir" | head -10
            fi
          done
        else
          echo "❌ No downloaded-results directory found"
        fi
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Prepare release assets
      id: prepare_release
      run: |
        echo "📦 Preparing release assets..."
        
        # Create timestamp
        TIMESTAMP=$(date -u +"%Y%m%d-%H%M%S")
        RELEASE_TAG="benchmark-results-${TIMESTAMP}"
        
        # Create release directory
        mkdir -p release-package
        
        echo "🔍 Checking for benchmark results..."
        
        # Check all possible locations for results
        RESULTS_FOUND=false
        
        # Process downloaded artifacts
        if [ -d "./downloaded-results" ]; then
          echo "📂 Found results in ./downloaded-results"
          echo "📊 Processing version directories:"
          ls -la ./downloaded-results/
          
          mkdir -p release-package/results
          
          for artifact_dir in downloaded-results/*/; do
            if [ -d "$artifact_dir" ]; then
              artifact_name=$(basename "$artifact_dir")
              echo "📦 Processing artifact: $artifact_name"
              
              # Extract version from artifact name (benchmark-results-node-X.Y.Z)
              version_name=$(echo "$artifact_name" | sed 's/benchmark-results-node-//')
              target_dir="release-package/results/node_$version_name"
              
              echo "📁 Target directory: $target_dir"
              mkdir -p "$target_dir"
              
              # Copy all contents from artifact to target directory
              if [ -d "$artifact_dir" ] && [ "$(ls -A "$artifact_dir")" ]; then
                echo "📂 Copying contents from artifact..."
                cp -r "$artifact_dir"/* "$target_dir/" 2>/dev/null || true
              fi
              
              echo "✅ Copied to: $target_dir"
              ls -la "$target_dir" || echo "Target directory is empty"
            fi
          done
          
          echo "✅ Copied benchmark data to release package"
          RESULTS_FOUND=true
        else
          echo "⚠️ No downloaded artifacts found"
        fi
        
        if [ "$RESULTS_FOUND" = false ]; then
          echo "❌ No benchmark results found, creating placeholder structure..."
          mkdir -p release-package/results/placeholder
          echo '{"message": "No benchmark data available", "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'"}' > release-package/results/placeholder/placeholder.json
        fi
        
        # Create manifest
        echo "📝 Creating release manifest..."
        
        # Count total files and calculate size
        TOTAL_FILES=$(find release-package -type f | wc -l)
        TOTAL_SIZE=$(du -sh release-package | cut -f1)
        
        # Get list of Node.js versions
        NODE_VERSIONS=$(find release-package/results -maxdepth 1 -name "node_*" -type d | sed 's|.*/node_||' | sort | tr '\n' ' ' | sed 's/ $//')
        
        {
          echo "{"
          echo "  \"releaseType\": \"benchmark-results\","
          echo "  \"generatedAt\": \"$(date -u -Iseconds)\","
          echo "  \"nodeVersions\": ["
          echo "$NODE_VERSIONS"
          echo "  ],"
          echo "  \"totalSize\": \"$TOTAL_SIZE\","
          echo "  \"workflowRun\": \"${{ github.run_id }}\","
          echo "  \"dataFiles\": $TOTAL_FILES,"
          echo "  \"note\": \"This release contains raw benchmark data and analysis files.\""
          echo "}"
        } > release-package/manifest.json
        
        # Create a compressed archive
        tar -czf "benchmark-results.tar.gz" -C release-package .
        
        echo "Release tag: $RELEASE_TAG"
        echo "Release assets prepared:"
        ls -la release-package/
        echo "Archive created: benchmark-results.tar.gz"
        
        # Set outputs for the next step
        echo "release_tag=${RELEASE_TAG}" >> $GITHUB_OUTPUT
        echo "archive_name=benchmark-results.tar.gz" >> $GITHUB_OUTPUT
        echo "generated_at=$(date -u -Iseconds)" >> $GITHUB_OUTPUT
    
    - name: Create Release
      id: create_release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ steps.prepare_release.outputs.release_tag }}
        release_name: "Benchmark Results - ${{ steps.prepare_release.outputs.release_tag }}"
        body: "## AsyncLocalStorage Benchmark Results\n\nThis release contains the latest benchmark results for AsyncLocalStorage performance across different Node.js versions.\n\n### What's Included\n- Raw benchmark data for each tested Node.js version\n- Memory profiling results\n- Performance metrics and timing data\n\n### Generated On\n${{ steps.prepare_release.outputs.generated_at }}\n\n### Workflow Run\n[${{ github.workflow }} #${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})\n\n### Usage\nDownload the `benchmark-results.tar.gz` file and extract it to use with the async-node-stats application."
        draft: false
        prerelease: false
    
    - name: Upload Release Asset
      uses: actions/upload-release-asset@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        upload_url: ${{ steps.create_release.outputs.upload_url }}
        asset_path: ./benchmark-results.tar.gz
        asset_name: benchmark-results.tar.gz
        asset_content_type: application/gzip
