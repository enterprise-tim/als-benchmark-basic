# GitHub Pages Setup for AsyncLocalStorage Benchmarks

## Overview

Your benchmark workflow now automatically deploys results to GitHub Pages after each run. This provides a public-facing website with interactive reports and visualizations.

## What Was Added

### 1. Workflow Permissions
Added GitHub Pages permissions to `.github/workflows/benchmark.yml`:
```yaml
permissions:
  contents: write
  actions: read
  pages: write      # NEW: Deploy to GitHub Pages
  id-token: write   # NEW: Required for Pages deployment
```

### 2. New Job: `deploy-to-pages`
A new job that runs after `compare-versions` and:
- Downloads the generated reports and data
- Prepares content for GitHub Pages
- Deploys to GitHub Pages using official actions

### 3. Documentation Files
Created in `docs/` directory:
- `index.html` - Beautiful landing page with statistics
- `README.md` - Documentation about the reports
- Existing files: `version-comparison.html`, JSON data files

## Enabling GitHub Pages

### Step 1: Enable GitHub Pages in Repository Settings

1. Go to your repository on GitHub
2. Click **Settings** → **Pages** (left sidebar)
3. Under "Build and deployment":
   - **Source**: Select "GitHub Actions"
   - Save the settings

### Step 2: Run the Workflow

You can trigger the workflow in several ways:

#### Option A: Push to Main Branch
```bash
git add .
git commit -m "Add GitHub Pages deployment"
git push origin main
```

#### Option B: Manual Trigger
1. Go to **Actions** tab in your repository
2. Click "AsyncLocalStorage Benchmark" workflow
3. Click "Run workflow" button
4. Select branch (main)
5. Set parameters (optional):
   - Iterations: 2 (default)
   - Run memory tests: true (default)
6. Click "Run workflow"

#### Option C: Scheduled Run
The workflow runs automatically every Sunday at 2 AM UTC (configured in the workflow).

### Step 3: Access Your Site

After the workflow completes successfully:

1. Go to **Settings** → **Pages**
2. You'll see: "Your site is live at `https://<username>.github.io/<repository-name>/`"
3. Click the link to view your benchmark results

For this repository:
```
https://tobrien.github.io/als-benchmark-basic/
```

## Workflow Execution Flow

```
┌─────────────────────┐
│  generate-matrix    │  Read Node.js versions from config
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│    benchmark        │  Run benchmarks in parallel for each version
│  (matrix strategy)  │  Upload results as artifacts
└──────────┬──────────┘
           │
           ▼
┌─────────────────────┐
│  compare-versions   │  Download all results
│                     │  Generate comparison reports
│                     │  Upload combined artifact
└──────────┬──────────┘
           │
           ├──────────────────────┐
           │                      │
           ▼                      ▼
┌─────────────────────┐  ┌─────────────────────┐
│  create-release     │  │  deploy-to-pages    │
│                     │  │                     │
│  Create GitHub      │  │  Deploy reports to  │
│  Release with data  │  │  GitHub Pages       │
└─────────────────────┘  └─────────────────────┘
```

## What Gets Deployed

The GitHub Pages site includes:

### Main Page (`index.html`)
- Overview statistics (versions tested, total results)
- Navigation cards to different reports
- Key findings and recommendations
- Methodology explanation
- Dynamic data loading from JSON files

### Version Comparison (`version-comparison.html`)
- Interactive charts showing performance trends
- Detailed comparison table
- Statistical analysis
- Color-coded performance indicators

### JSON Data Files
- `version-comparison.json` - Complete benchmark data
- `performance-report.json` - Detailed analysis
- `performance-summary.json` - Quick metrics

### Results Data
- Raw benchmark files in `results/` directory
- Per-version iteration data
- Memory test results

## Customization

### Changing the Site Appearance

Edit `docs/index.html` to customize:
- Colors and styling (inline `<style>` section)
- Layout and content
- Statistics displayed
- Navigation structure

### Adding More Reports

1. Create new HTML files in `docs/`
2. Add navigation links in `index.html`
3. Ensure data files are generated by the workflow

### Modifying Report Generation

Edit these files to change what data is collected:
- `src/version-comparison.js` - Version comparison logic
- `src/report-generator.js` - Performance report generation
- `src/benchmark.js` - Benchmark execution

## Testing Locally

### Run Benchmarks Locally
```bash
# Run benchmarks (2 iterations)
npm run multi-iteration 2

# Generate comparison report
npm run compare-versions

# Generate performance reports
npm run generate-report
```

### View Reports Locally
```bash
# Simple HTTP server (Python 3)
cd docs
python3 -m http.server 8000

# Then open: http://localhost:8000
```

Or simply open `docs/index.html` in your browser.

## Troubleshooting

### Pages Not Deploying

**Check Permissions:**
- Verify `pages: write` and `id-token: write` are in workflow permissions
- Ensure GitHub Actions has permission to deploy Pages in repository settings

**Check Workflow Status:**
```bash
# View workflow runs
gh run list --workflow=benchmark.yml

# View specific run details
gh run view <run-id>
```

**Check Logs:**
1. Go to Actions tab
2. Click on the workflow run
3. Expand "deploy-to-pages" job
4. Check each step for errors

### Missing Data on Site

**Verify Artifacts:**
- Check that `compare-versions` job completed successfully
- Verify "version-comparison" artifact was uploaded
- Check artifact contents in workflow logs

**Check File Paths:**
- Ensure `docs/` directory exists
- Verify JSON files are present
- Check browser console for 404 errors

### Charts Not Displaying

**CDN Issues:**
- Charts use Chart.js from CDN
- Check browser console for loading errors
- Verify internet connection

**Data Format Issues:**
- Check JSON files are valid
- Verify chart data structure matches Chart.js format
- Look for JavaScript errors in console

### Workflow Fails

**Common Issues:**
1. **No benchmark data:** Check that benchmark jobs completed
2. **Artifact not found:** Verify artifact names match between upload/download
3. **Permission denied:** Check workflow permissions
4. **Node version issues:** Verify versions in `config/node-versions.json`

**Debug Steps:**
```bash
# Test locally first
npm run multi-iteration 2
npm run compare-versions
npm run generate-report

# Check generated files
ls -la docs/
ls -la public/results/versions/
```

## Monitoring

### View Deployment Status

**GitHub UI:**
1. Go to **Actions** tab
2. Click on latest workflow run
3. Check "deploy-to-pages" job status

**GitHub CLI:**
```bash
# List recent runs
gh run list --workflow=benchmark.yml --limit 5

# Watch a running workflow
gh run watch
```

### View Site Analytics

Enable GitHub Pages analytics in repository settings to track:
- Page views
- Visitor statistics
- Popular pages

## Next Steps

### Recommended Enhancements

1. **Add More Visualizations:**
   - Time series charts showing performance over time
   - Heatmaps for version comparisons
   - Box plots for statistical distribution

2. **Interactive Features:**
   - Filter results by Node.js version
   - Compare specific versions side-by-side
   - Download raw data as CSV

3. **Historical Data:**
   - Store results from each run
   - Show performance trends over time
   - Compare current vs. previous runs

4. **Custom Domain:**
   - Set up a custom domain for your GitHub Pages site
   - Configure DNS settings
   - Update repository settings

5. **SEO Optimization:**
   - Add meta tags for better search visibility
   - Create sitemap.xml
   - Add Open Graph tags for social sharing

## Resources

- [GitHub Pages Documentation](https://docs.github.com/en/pages)
- [GitHub Actions for Pages](https://github.com/actions/deploy-pages)
- [Chart.js Documentation](https://www.chartjs.org/docs/)
- [AsyncLocalStorage API](https://nodejs.org/api/async_context.html#class-asynclocalstorage)

## Support

For issues or questions:
1. Check workflow logs in GitHub Actions
2. Review this documentation
3. Check the repository issues
4. Test locally to isolate the problem

